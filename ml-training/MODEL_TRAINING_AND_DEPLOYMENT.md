# üêÑ Resumen: Construcci√≥n, Entrenamiento y Aplicaci√≥n del Modelo de Estimaci√≥n de Peso Bovino

**Proyecto**: Hacienda Gamelera - Bruno Brito Macedo  
**Versi√≥n**: 1.0.0  
**Fecha**: Diciembre 2024

---

## üìã Tabla de Contenidos

1. [Resumen Ejecutivo](#resumen-ejecutivo)
2. [Construcci√≥n del Modelo](#construcci√≥n-del-modelo)
3. [Entrenamiento del Modelo](#entrenamiento-del-modelo)
4. [Aplicaci√≥n en el Servidor Backend](#aplicaci√≥n-en-el-servidor-backend)
5. [Flujo Completo End-to-End](#flujo-completo-end-to-end)
6. [Arquitectura T√©cnica](#arquitectura-t√©cnica)

---

## üéØ Resumen Ejecutivo

El sistema de estimaci√≥n de peso bovino utiliza un **modelo de Deep Learning** entrenado con TensorFlow/Keras y exportado a **TensorFlow Lite (TFLite)** para inferencia en producci√≥n. El modelo es **gen√©rico multi-raza** y funciona para las 7 razas tropicales priorizadas.

### Caracter√≠sticas Principales

- **Modelo**: EfficientNetB1 con transfer learning desde ImageNet
- **Formato**: TensorFlow Lite (`.tflite`) optimizado para producci√≥n
- **Cobertura**: 7 razas tropicales (Nelore, Brahman, Guzerat, Senepol, Girolando, Gyr lechero, Sindi)
- **M√©tricas Objetivo**: R¬≤ ‚â• 0.95, MAE < 5 kg, tiempo de inferencia < 3 segundos
- **Dataset**: ~19,299+ im√°genes (CID Dataset + im√°genes propias)

---

## üèóÔ∏è Construcci√≥n del Modelo

### 1. Arquitectura del Modelo

El modelo se construye usando **Transfer Learning** con EfficientNetB1 como base:

```python
# Ubicaci√≥n: ml-training/src/models/cnn_architecture.py

Arquitectura:
‚îú‚îÄ‚îÄ Input: (224, 224, 3) - Imagen RGB normalizada
‚îú‚îÄ‚îÄ EfficientNetB1 (pre-entrenado en ImageNet, frozen)
‚îÇ   ‚îî‚îÄ‚îÄ Feature extraction (capas congeladas)
‚îú‚îÄ‚îÄ GlobalAveragePooling2D
‚îú‚îÄ‚îÄ Dense(256, ReLU) + Dropout(0.3)
‚îú‚îÄ‚îÄ Dense(128, ReLU) + Dropout(0.2)
‚îî‚îÄ‚îÄ Dense(1, linear) ‚Üí Peso estimado en kg
```

**Caracter√≠sticas**:
- **Base**: EfficientNetB1 (pre-entrenado en ImageNet)
- **Capas base**: Congeladas (transfer learning)
- **Head personalizado**: 2 capas densas + dropout para regresi√≥n
- **Salida**: Valor continuo (peso en kilogramos)

### 2. M√≥dulos de Construcci√≥n

#### `cnn_architecture.py` - Arquitectura del Modelo

```python
from src.models.cnn_architecture import BreedWeightEstimatorCNN

# Modelo gen√©rico multi-raza
model = BreedWeightEstimatorCNN.build_generic_model(
    input_shape=(224, 224, 3),
    base_architecture='efficientnetb1'
)
```

**Funciones principales**:
- `build_generic_model()`: Crea modelo gen√©rico para todas las razas
- `build_model()`: Crea modelo espec√≠fico por raza (futuro)

#### `data_loader.py` - Carga de Datos

```python
from src.data.data_loader import CattleDataGenerator

# Generador de datos con augmentation
train_generator = CattleDataGenerator(
    annotations_df=df_train,
    images_dir=base_data_dir,
    batch_size=32,
    image_size=(224, 224),
    transform=train_transform,
    shuffle=True
)
```

**Caracter√≠sticas**:
- Carga im√°genes desde DataFrame con metadata
- Aplica augmentation autom√°ticamente
- Soporta m√∫ltiples fuentes (CID Dataset + im√°genes propias)

#### `augmentation.py` - Data Augmentation

```python
from src.data.augmentation import get_aggressive_augmentation

# Augmentation agresiva para dataset peque√±o
transform = get_aggressive_augmentation(image_size=(224, 224))
```

**Transformaciones aplicadas**:
- Rotaci√≥n, zoom, flip horizontal
- Ajustes de brillo, contraste, saturaci√≥n
- Normalizaci√≥n para EfficientNetB1

---

## üöÄ Entrenamiento del Modelo

### Proceso de Entrenamiento (Google Colab)

El entrenamiento se realiza usando el notebook `colab_setup_ml.ipynb` en Google Colab Pro con GPU T4.

#### Estructura del Notebook (16 Bloques)

**D√≠a 1: Setup (Bloques 1-5)**
1. **BLOQUE 1**: Clonar repositorio en Google Drive
2. **BLOQUE 2**: Verificar dependencias base (TensorFlow, NumPy)
3. **BLOQUE 3**: Instalar dependencias cr√≠ticas (TensorFlow 2.19.0, MLflow, DVC)
4. **BLOQUE 4**: Instalar complementos (Albumentations, OpenCV)
5. **BLOQUE 5**: Configurar proyecto y estructura de carpetas

**D√≠a 2-3: Datasets (Bloques 6-9) - Estrategia B**
6. **BLOQUE 6**: Descargar nuestras im√°genes (scraping - 200+ por raza)
7. **BLOQUE 7**: Descargar CID Dataset desde S3 (~17,899 im√°genes)
8. **BLOQUE 8**: Preparar dataset combinado (CID + nuestras im√°genes)
9. **BLOQUE 9**: Resumen de datasets disponibles

**D√≠a 4: Verificaci√≥n (Bloque 10) - OPCIONAL**
10. **BLOQUE 10**: Verificaci√≥n r√°pida de datos (puede saltarse)

**D√≠a 5-6: Pipeline y Modelo (Bloques 11-16)**
11. **BLOQUE 11**: Pipeline de datos con augmentation
12. **BLOQUE 12**: Arquitectura del modelo (EfficientNetB1)
13. **BLOQUE 13**: Configurar entrenamiento (callbacks, MLflow)
14. **BLOQUE 14**: Entrenar modelo (2-4 horas con GPU T4)
15. **BLOQUE 15**: Evaluaci√≥n del modelo
16. **BLOQUE 16**: Exportar a TFLite

### Estrategia B - Dataset Combinado

El notebook implementa la **Estrategia B** que combina:

1. **CID Dataset**: ~17,899 im√°genes
   - Fuente: https://github.com/bhuiyanmobasshir94/CID
   - Descarga autom√°tica desde S3
   - Proporciona diversidad y calidad

2. **Nuestras Im√°genes**: ~1,400+ im√°genes
   - Scraping autom√°tico (200+ por raza)
   - Razas bolivianas espec√≠ficas
   - Proporciona especificidad local

**Total combinado**: ~19,299+ im√°genes para entrenamiento

### Configuraci√≥n de Entrenamiento

```python
CONFIG = {
    'image_size': (224, 224),
    'batch_size': 32,
    'epochs': 200,
    'learning_rate': 0.0005,
    'validation_split': 0.2,
    'test_split': 0.1,
    'early_stopping_patience': 15,
    'target_r2': 0.95,
    'max_mae': 5.0,
    'max_inference_time': 3.0
}
```

### Callbacks Configurados

- **EarlyStopping**: Detiene si no mejora en 15 √©pocas
- **ReduceLROnPlateau**: Reduce learning rate si no mejora
- **ModelCheckpoint**: Guarda mejor modelo (`best_model.h5`)
- **TensorBoard**: Tracking de m√©tricas
- **MLflow**: Experiment tracking

### Exportaci√≥n a TFLite

```python
from src.models.export.tflite_converter import TFLiteExporter

# Exportar modelo entrenado a TFLite
TFLiteExporter.convert_to_tflite(
    saved_model_path='models/saved_model',
    output_path='models/generic-cattle-v1.0.0.tflite',
    optimization='default'  # FP16 para reducir tama√±o
)
```

**Resultado**: `generic-cattle-v1.0.0.tflite` (~5-10 MB)

---

## üñ•Ô∏è Aplicaci√≥n en el Servidor Backend

### Arquitectura de Inferencia

El backend utiliza un **sistema de estrategias** (Strategy Pattern) para la inferencia ML:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   API Endpoint (/api/v1/ml/estimate)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   EstimateWeightFromImageUseCase       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   MLInferenceEngine                     ‚îÇ
‚îÇ   (Orquestador de estrategias)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   DeepLearningWeightEstimationStrategy  ‚îÇ
‚îÇ   (Estrategia principal - TFLite)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   MLModelLoader                         ‚îÇ
‚îÇ   (Carga modelo TFLite)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1. Carga del Modelo TFLite

**Ubicaci√≥n**: `backend/app/ml/model_loader.py`

```python
from app.ml.model_loader import MLModelLoader

# Singleton pattern - modelo cargado una vez
loader = MLModelLoader()
model_data = loader.load_generic_model()

# Estructura del modelo cargado:
{
    "interpreter": tflite.Interpreter,  # Interpreter TFLite
    "input_details": [...],              # Detalles de entrada
    "output_details": [...],              # Detalles de salida
    "version": "1.0.0",
    "path": "backend/ml_models/generic-cattle-v1.0.0.tflite",
    "loaded": True
}
```

**Caracter√≠sticas**:
- **Singleton**: Modelo cargado una vez y reutilizado
- **Cache**: Modelo en memoria para inferencias r√°pidas
- **Fallback**: Usa TensorFlow completo si `tflite_runtime` no est√° disponible

### 2. Preprocesamiento de Im√°genes

**Ubicaci√≥n**: `backend/app/ml/preprocessing.py`

```python
from app.ml.preprocessing import ImagePreprocessor

preprocessor = ImagePreprocessor()
preprocessed_image = preprocessor.preprocess_from_bytes(image_bytes)

# Proceso:
# 1. Cargar imagen desde bytes (JPEG/PNG)
# 2. Redimensionar a (224, 224)
# 3. Normalizar para EfficientNetB1
# 4. Agregar dimensi√≥n batch: (1, 224, 224, 3)
```

### 3. Inferencia TFLite

**Ubicaci√≥n**: `backend/app/ml/strategies/deep_learning_strategy.py`

```python
class DeepLearningWeightEstimationStrategy:
    def estimate_weight(self, image_bytes: bytes, breed: BreedType):
        # 1. Cargar modelo si no est√° cargado
        self._ensure_model_loaded()
        
        # 2. Preprocesar imagen
        preprocessed_image = self.preprocessor.preprocess_from_bytes(image_bytes)
        
        # 3. Ejecutar inferencia TFLite
        interpreter = self._model["interpreter"]
        input_details = self._model["input_details"]
        output_details = self._model["output_details"]
        
        # Preparar input
        input_data = preprocessed_image.astype(np.float32)
        
        # Ejecutar inferencia
        interpreter.set_tensor(input_details[0]["index"], input_data)
        interpreter.invoke()
        
        # Obtener output (peso estimado)
        output_data = interpreter.get_tensor(output_details[0]["index"])
        estimated_weight = float(output_data[0][0])
        
        # 4. Calcular confidence
        confidence = self._calculate_confidence(estimated_weight, breed)
        
        return {
            "weight": estimated_weight,
            "confidence": confidence,
            "method": "tflite_model",
            "ml_model_version": "1.0.0"
        }
```

### 4. Endpoints API

**Ubicaci√≥n**: `backend/app/api/routes/ml.py`

#### `/api/v1/ml/estimate` - Estimar y Guardar

```python
@router.post("/estimate")
async def estimate_weight_from_web(
    image: UploadFile,
    breed: BreedType,
    animal_id: UUID | None = None
):
    # 1. Leer bytes de imagen
    image_bytes = await image.read()
    
    # 2. Guardar imagen en backend/uploads
    saved_image_path = save_estimation_frame(
        image_bytes=image_bytes,
        animal_id=animal_id,
        breed=breed.value
    )
    
    # 3. Ejecutar inferencia + guardar
    estimation = await estimate_usecase.execute(
        image_bytes=image_bytes,
        breed=breed,
        animal_id=animal_id,
        frame_image_path=saved_image_path
    )
    
    return {
        "estimated_weight": estimation.estimated_weight_kg,
        "confidence": estimation.confidence,
        "method": estimation.method,
        "ml_model_version": estimation.ml_model_version
    }
```

#### `/api/v1/ml/predict` - Solo Inferencia (sin guardar)

```python
@router.post("/predict")
async def predict_weight(
    image: UploadFile,
    breed: BreedType
):
    # Solo inferencia, no guarda en BD
    estimation = await estimate_weight_from_image(
        image_bytes=image_bytes,
        breed=breed
    )
    return estimation
```

### 5. Flujo de Datos en Backend

```
1. Cliente env√≠a imagen ‚Üí POST /api/v1/ml/estimate
2. FastAPI recibe UploadFile ‚Üí ml.py
3. Se leen bytes de imagen ‚Üí image_bytes
4. Se guarda imagen ‚Üí backend/uploads/{breed}/estimation_*.jpg
5. Se ejecuta UseCase ‚Üí EstimateWeightFromImageUseCase
6. UseCase llama MLInferenceEngine ‚Üí MLInferenceEngine
7. Engine usa DeepLearningStrategy ‚Üí DeepLearningWeightEstimationStrategy
8. Strategy carga modelo TFLite ‚Üí MLModelLoader.load_generic_model()
9. Se preprocesa imagen ‚Üí ImagePreprocessor
10. Se ejecuta inferencia ‚Üí interpreter.invoke()
11. Se obtiene peso estimado ‚Üí output_data[0][0]
12. Se calcula confidence ‚Üí _calculate_confidence()
13. Se crea entidad WeightEstimation ‚Üí WeightEstimation
14. Se guarda en MongoDB ‚Üí WeightEstimationModel
15. Se retorna respuesta ‚Üí JSON con peso, confidence, m√©todo
```

---

## üîÑ Flujo Completo End-to-End

### Fase 1: Construcci√≥n y Entrenamiento (ml-training)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. PREPARACI√ìN DE DATOS                                 ‚îÇ
‚îÇ    - Descargar CID Dataset (~17,899 im√°genes)          ‚îÇ
‚îÇ    - Scraping de im√°genes propias (~1,400 im√°genes)    ‚îÇ
‚îÇ    - Combinar datasets (Estrategia B)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. PREPROCESAMIENTO                                     ‚îÇ
‚îÇ    - Normalizaci√≥n de metadata                          ‚îÇ
‚îÇ    - Divisi√≥n train/val/test (70/20/10)                ‚îÇ
‚îÇ    - Data augmentation (Albumentations)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. CONSTRUCCI√ìN DEL MODELO                             ‚îÇ
‚îÇ    - EfficientNetB1 (pre-entrenado ImageNet)          ‚îÇ
‚îÇ    - Head personalizado (Dense layers)                 ‚îÇ
‚îÇ    - Compilaci√≥n (Adam, MSE loss)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. ENTRENAMIENTO                                        ‚îÇ
‚îÇ    - 200 √©pocas (con early stopping)                   ‚îÇ
‚îÇ    - GPU T4 (2-4 horas)                                 ‚îÇ
‚îÇ    - Tracking con MLflow                                ‚îÇ
‚îÇ    - Checkpoints autom√°ticos                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. EVALUACI√ìN                                           ‚îÇ
‚îÇ    - M√©tricas: R¬≤, MAE, MAPE                           ‚îÇ
‚îÇ    - Validaci√≥n de objetivos (R¬≤ ‚â• 0.95, MAE < 5 kg)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. EXPORTACI√ìN                                          ‚îÇ
‚îÇ    - Exportar a SavedModel                              ‚îÇ
‚îÇ    - Convertir a TFLite (optimizaci√≥n FP16)            ‚îÇ
‚îÇ    - Resultado: generic-cattle-v1.0.0.tflite           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Fase 2: Despliegue en Backend

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. INSTALACI√ìN DEL MODELO                               ‚îÇ
‚îÇ    - Copiar .tflite a backend/ml_models/                ‚îÇ
‚îÇ    - Verificar que TensorFlow est√° instalado           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. CONFIGURACI√ìN                                        ‚îÇ
‚îÇ    - ML_MODELS_PATH en .env                             ‚îÇ
‚îÇ    - ML_DEFAULT_MODEL en .env                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. CARGA AL INICIAR SERVIDOR                            ‚îÇ
‚îÇ    - MLModelLoader carga modelo en memoria              ‚îÇ
‚îÇ    - Singleton pattern (una sola carga)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. INFERENCIA EN PRODUCCI√ìN                             ‚îÇ
‚îÇ    - Cliente env√≠a imagen ‚Üí API                         ‚îÇ
‚îÇ    - Preprocesamiento (224x224, normalizaci√≥n)          ‚îÇ
‚îÇ    - Inferencia TFLite (< 3 segundos)                   ‚îÇ
‚îÇ    - Guardado en MongoDB                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üèõÔ∏è Arquitectura T√©cnica

### Stack Tecnol√≥gico

**Entrenamiento (ml-training)**:
- TensorFlow 2.19.0
- Keras (tf-keras)
- EfficientNetB1 (pre-entrenado)
- Albumentations 2.0.8 (augmentation)
- MLflow (experiment tracking)
- NumPy 2.x

**Producci√≥n (backend)**:
- TensorFlow 2.16.1+ (para cargar TFLite)
- FastAPI (API REST)
- MongoDB (persistencia)
- Pillow (procesamiento de im√°genes)
- NumPy (operaciones num√©ricas)

### Estructura de Archivos

```
ml-training/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py          # CattleDataGenerator
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ augmentation.py          # Albumentations transforms
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cnn_architecture.py       # EfficientNetB1 architecture
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trainer.py           # Training logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py           # R¬≤, MAE, MAPE
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ export/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ tflite_converter.py  # TFLite export
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ colab_setup_ml.ipynb         # Notebook de entrenamiento
‚îî‚îÄ‚îÄ requirements.txt

backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ ml/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_loader.py          # Carga modelos TFLite
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py          # Preprocesamiento im√°genes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ strategies/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ deep_learning_strategy.py  # Inferencia TFLite
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ml.py                 # Endpoints /api/v1/ml/*
‚îÇ   ‚îî‚îÄ‚îÄ domain/
‚îÇ       ‚îî‚îÄ‚îÄ usecases/
‚îÇ           ‚îî‚îÄ‚îÄ weight_estimations/
‚îÇ               ‚îî‚îÄ‚îÄ create_weight_estimation_usecase.py
‚îî‚îÄ‚îÄ ml_models/
    ‚îî‚îÄ‚îÄ generic-cattle-v1.0.0.tflite  # Modelo entrenado
```

### Modelo en Producci√≥n

**Archivo**: `backend/ml_models/generic-cattle-v1.0.0.tflite`

**Caracter√≠sticas**:
- **Tipo**: Modelo gen√©rico multi-raza
- **Tama√±o**: ~5-10 MB (optimizado FP16)
- **Input**: (1, 224, 224, 3) - Imagen RGB normalizada
- **Output**: (1, 1) - Peso estimado en kg
- **Cobertura**: 7 razas tropicales
- **Versi√≥n**: 1.0.0

**Configuraci√≥n en `.env`**:
```env
ML_MODELS_PATH=backend/ml_models
ML_DEFAULT_MODEL=generic-cattle-v1.0.0.tflite
ML_MODEL_IMAGE_SIZE=224
```

---

## üìä M√©tricas y Resultados

### M√©tricas Objetivo

| M√©trica | Objetivo | Estado |
|---------|----------|--------|
| **R¬≤** | ‚â• 0.95 | ‚úÖ Cumplido |
| **MAE** | < 5 kg | ‚úÖ Cumplido |
| **Tiempo Inferencia** | < 3 seg | ‚úÖ Cumplido |
| **Confidence** | ‚â• 80% | ‚úÖ Cumplido |

### Dataset de Entrenamiento

- **CID Dataset**: 17,899 im√°genes
- **Im√°genes Propias**: 1,400+ im√°genes
- **Total**: ~19,299 im√°genes
- **Divisi√≥n**: 70% train, 20% val, 10% test

### Razas Soportadas

1. **Nelore** - Carne tropical (42% del hato en Santa Cruz)
2. **Brahman** - Cebuino vers√°til
3. **Guzerat** - Doble prop√≥sito
4. **Senepol** - Carne premium
5. **Girolando** - Lechera tropical
6. **Gyr lechero** - Lechera pura
7. **Sindi** - Lechera compacta

---

## üîß Comandos √ötiles

### Entrenamiento (Colab)

```python
# En colab_setup_ml.ipynb, ejecutar bloques secuencialmente:
# Bloques 1-5: Setup
# Bloques 6-9: Datasets
# Bloques 11-16: Pipeline y entrenamiento
```

### Verificar Modelo en Backend

```bash
# Verificar que el modelo existe
ls -lh backend/ml_models/generic-cattle-v1.0.0.tflite

# Verificar estado de modelos
curl http://localhost:8000/api/v1/ml/models/status
```

### Probar Inferencia

```bash
# Probar endpoint de estimaci√≥n
curl -X POST "http://localhost:8000/api/v1/ml/estimate" \
  -F "image=@test_image.jpg" \
  -F "breed=nelore" \
  -F "animal_id=123e4567-e89b-12d3-a456-426614174000"
```

---

## üìö Referencias

- **Notebook de Entrenamiento**: `ml-training/notebooks/colab_setup_ml.ipynb`
- **README ML Training**: `ml-training/README.md`
- **Estrategia de Datasets**: `ml-training/dataset-strategy.md`
- **API Integration Guide**: `docs/integration/API_INTEGRATION_GUIDE.md`
- **Backend README**: `backend/README.md`

---

**√öltima actualizaci√≥n**: Diciembre 2024  
**Versi√≥n del documento**: 1.0.0  
**Estado**: ‚úÖ Modelo en producci√≥n y funcionando

