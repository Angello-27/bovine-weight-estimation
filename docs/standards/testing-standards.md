# Est√°ndares de Testing

Sistema de Estimaci√≥n de Peso Bovino - Hacienda Gamelera

## 1. Cobertura de Testing

### 1.1 Cobertura M√≠nima Requerida

- **Cobertura general**: 70% m√≠nimo
- **Casos cr√≠ticos**: 100% obligatorio
- **Funcionalidades normativas**: 100% obligatorio

### 1.2 Casos Cr√≠ticos (100% Cobertura Obligatoria)

```dart
// Flutter - Casos cr√≠ticos
‚úÖ Evaluaci√≥n de calidad de fotogramas (5 criterios)
‚úÖ Selecci√≥n del mejor fotograma (score ponderado)
‚úÖ Validaci√≥n de las 7 razas espec√≠ficas
‚úÖ C√°lculo de categor√≠as de edad (4 categor√≠as)
‚úÖ Generaci√≥n de GMA (Gu√≠a de Movimiento Animal)
‚úÖ Validaci√≥n de cumplimiento REGENSA (cap√≠tulos 3.10 y 7.1)
‚úÖ Procesamiento offline-first con SQLite
‚úÖ Sincronizaci√≥n con resoluci√≥n de conflictos

// Python - Casos cr√≠ticos
‚úÖ Validaci√≥n de razas bovinas (7 razas)
‚úÖ C√°lculo de m√©tricas de precisi√≥n (‚â•95%, R¬≤ ‚â• 0.95)
‚úÖ Generaci√≥n de reportes SENASAG (PDF/CSV/XML)
‚úÖ Integraci√≥n con Gran Paitit√≠
‚úÖ Validaci√≥n de cumplimiento normativo
‚úÖ Procesamiento de modelos ML por raza
```

## 2. Estructura de Tests

### 2.1 Organizaci√≥n por Tecnolog√≠a

```text
# Flutter Tests
test/
‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îú‚îÄ‚îÄ data_management/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ domain/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ usecases/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ start_continuous_capture_usecase_test.dart
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluate_frame_quality_usecase_test.dart
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ select_best_frame_usecase_test.dart
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ process_by_breed_usecase_test.dart
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ presentation/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ providers/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ camera_provider_test.dart
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ frame_evaluation_provider_test.dart
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ widgets/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ breed_selector_widget_test.dart
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ frame_quality_indicator_test.dart
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ domain/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ usecases/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate_senasag_report_usecase_test.dart
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ create_gma_usecase_test.dart
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validate_regensa_compliance_usecase_test.dart
‚îÇ   ‚îÇ
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ breed_validator_test.dart
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ age_category_calculator_test.dart
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ frame_quality_calculator_test.dart
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ precision_calculator_test.dart

# Python Tests
tests/
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_capture_sessions.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_gma_management.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_senasag_reports.py
‚îÇ
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ test_capture_service.py
‚îÇ   ‚îú‚îÄ‚îÄ test_frame_evaluation_service.py
‚îÇ   ‚îú‚îÄ‚îÄ test_gma_service.py
‚îÇ   ‚îú‚îÄ‚îÄ test_regensa_compliance_service.py
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ test_capture_session.py
‚îÇ   ‚îú‚îÄ‚îÄ test_breed.py
‚îÇ   ‚îú‚îÄ‚îÄ test_gma.py
‚îÇ
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ test_breed_validator.py
‚îÇ   ‚îú‚îÄ‚îÄ test_frame_quality_calculator.py
‚îÇ   ‚îú‚îÄ‚îÄ test_precision_metrics.py
```

## 3. Tests Espec√≠ficos del Dominio

### 3.1 Tests de Validaci√≥n de Razas (Flutter)

```dart
// test/core/utils/breed_validator_test.dart
import 'package:flutter_test/flutter_test.dart';
import 'package:bovine_weight_estimation/core/utils/breed_validator.dart';
import 'package:bovine_weight_estimation/core/constants/breeds.dart';

void main() {
  group('BreedValidator - Validaci√≥n de 7 Razas Espec√≠ficas', () {
    late BreedValidator validator;
    
    setUp(() {
      validator = BreedValidator();
    });
    
    test('should validate all 7 breeds from Hacienda Gamelera', () {
      // Arrange
      final validBreeds = [
        BreedType.brahman,
        BreedType.nelore,
        BreedType.angus,
        BreedType.cebuinas,
        BreedType.criollo,
        BreedType.pardoSuizo,
        BreedType.jersey,
      ];
      
      // Act & Assert
      for (final breed in validBreeds) {
        expect(validator.isValid(breed), true, 
          reason: '${breed.toString()} debe ser v√°lida para Hacienda Gamelera');
      }
    });
    
    test('should return breed count of exactly 7', () {
      expect(BreedType.values.length, 7,
        reason: 'Deben ser exactamente las 7 razas de Hacienda Gamelera');
    });
    
    test('should reject invalid breeds not in Hacienda Gamelera', () {
      // Arrange
      final invalidBreeds = ['holstein', 'hereford', 'charolais'];
      
      // Act & Assert
      for (final breedName in invalidBreeds) {
        expect(() => validator.validateBreed(breedName), 
          throwsA(isA<InvalidBreedFailure>()),
          reason: '$breedName no est√° presente en Hacienda Gamelera');
      }
    });
    
    test('should validate scientific names correctly', () {
      // Arrange & Act
      final brahman = validator.getBreedInfo(BreedType.brahman);
      final cebuinas = validator.getBreedInfo(BreedType.cebuinas);
      final criollo = validator.getBreedInfo(BreedType.criollo);
      
      // Assert
      expect(brahman.scientificName, 'Bos indicus');
      expect(cebuinas.scientificName, 'Bos indicus');
      expect(criollo.scientificName, 'Bos taurus');
    });
  });
}
```

### 3.2 Tests de Evaluaci√≥n de Fotogramas (Flutter)

```dart
// test/features/data_management/domain/usecases/evaluate_frame_quality_usecase_test.dart
import 'package:flutter_test/flutter_test.dart';
import 'package:mockito/mockito.dart';
import 'package:bovine_weight_estimation/features/data_management/domain/usecases/evaluate_frame_quality_usecase.dart';
import 'package:bovine_weight_estimation/core/constants/capture_constants.dart';

void main() {
  group('EvaluateFrameQualityUseCase - Criterios de Calidad', () {
    late EvaluateFrameQualityUseCase useCase;
    late MockFrameDataRepository mockRepository;
    
    setUp(() {
      mockRepository = MockFrameDataRepository();
      useCase = EvaluateFrameQualityUseCase(mockRepository);
    });
    
    test('should accept frame with all quality metrics above threshold', () async {
      // Arrange
      final frameData = MockFrameData();
      when(frameData.sharpness).thenReturn(0.85);  // > 0.7 ‚úÖ
      when(frameData.brightness).thenReturn(0.6);   // 0.4-0.8 ‚úÖ
      when(frameData.contrast).thenReturn(0.7);     // > 0.5 ‚úÖ
      when(frameData.silhouetteVisibility).thenReturn(0.9);  // > 0.8 ‚úÖ
      when(frameData.angleScore).thenReturn(0.75);  // > 0.6 ‚úÖ
      
      // Act
      final result = await useCase(frameData: frameData);
      
      // Assert
      expect(result.isRight(), true);
      result.fold(
        (failure) => fail('Should not fail with valid frame'),
        (frameQuality) {
          expect(frameQuality.overallScore, greaterThan(CaptureConstants.minOverallScore));
          expect(frameQuality.isAcceptable, true);
          expect(frameQuality.rejectionReason, isNull);
        },
      );
    });
    
    test('should reject frame with low silhouette visibility (<0.8)', () async {
      // Arrange
      final frameData = MockFrameData();
      when(frameData.sharpness).thenReturn(0.85);
      when(frameData.brightness).thenReturn(0.6);
      when(frameData.contrast).thenReturn(0.7);
      when(frameData.silhouetteVisibility).thenReturn(0.5);  // < 0.8 ‚ùå
      when(frameData.angleScore).thenReturn(0.75);
      
      // Act
      final result = await useCase(frameData: frameData);
      
      // Assert
      result.fold(
        (failure) => fail('Should not fail'),
        (frameQuality) {
          expect(frameQuality.isAcceptable, false);
          expect(frameQuality.rejectionReason, contains('silueta'));
          expect(frameQuality.overallScore, lessThan(CaptureConstants.minOverallScore));
        },
      );
    });
    
    test('should calculate weighted overall score correctly', () async {
      // Arrange: Valores espec√≠ficos para verificar pesos del ADR-010
      final frameData = MockFrameData();
      when(frameData.sharpness).thenReturn(0.8);
      when(frameData.brightness).thenReturn(0.6);
      when(frameData.silhouetteVisibility).thenReturn(0.9);
      when(frameData.angleScore).thenReturn(0.7);
      
      // Act
      final result = await useCase(frameData: frameData);
      
      // Assert
      result.fold(
        (failure) => fail('Should not fail'),
        (frameQuality) {
          // Score esperado: (0.9*0.4) + (0.8*0.3) + (0.6*0.2) + (0.7*0.1) = 0.79
          final expectedScore = (0.9 * CaptureConstants.silhouetteWeight) +
                               (0.8 * CaptureConstants.sharpnessWeight) +
                               (0.6 * CaptureConstants.brightnessWeight) +
                               (0.7 * CaptureConstants.angleWeight);
          expect(frameQuality.overallScore, closeTo(expectedScore, 0.01));
        },
      );
    });
    
    test('should reject frame with insufficient sharpness (<0.7)', () async {
      // Arrange
      final frameData = MockFrameData();
      when(frameData.sharpness).thenReturn(0.5);  // < 0.7 ‚ùå
      when(frameData.brightness).thenReturn(0.6);
      when(frameData.contrast).thenReturn(0.7);
      when(frameData.silhouetteVisibility).thenReturn(0.9);
      when(frameData.angleScore).thenReturn(0.75);
      
      // Act
      final result = await useCase(frameData: frameData);
      
      // Assert
      result.fold(
        (failure) => fail('Should not fail'),
        (frameQuality) {
          expect(frameQuality.isAcceptable, false);
          expect(frameQuality.rejectionReason, contains('nitidez'));
        },
      );
    });
  });
}
```

### 3.3 Tests de Integraci√≥n Normativa (Python)

```python
# tests/services/test_regensa_compliance_service.py
import pytest
from unittest.mock import Mock
from app.services.monitoring.regensa_compliance_service import REGENSAComplianceService
from app.models.regensa_compliance import REGENSACompliance
from app.core.exceptions import REGENSAComplianceException

class TestREGENSAComplianceService:
    @pytest.fixture
    def service(self):
        return REGENSAComplianceService()
    
    def test_should_validate_chapter_3_10_requirements_centros_concentracion(self, service):
        """Test validaci√≥n de cap√≠tulo 3.10 - Centros de concentraci√≥n animal"""
        # Arrange
        farm_data = Mock()
        farm_data.has_antislip_ramps = True
        farm_data.corridor_width_meters = 1.8      # ‚â• 1.6m ‚úÖ
        farm_data.space_per_animal_m2 = 2.5         # ‚â• 2m¬≤ ‚úÖ
        farm_data.has_disinfection_system = True
        farm_data.has_quarantine_corral = True
        farm_data.prohibits_pain_instruments = True
        
        # Act
        result = service.validate_chapter_3_10(farm_data)
        
        # Assert
        assert result.is_compliant is True
        assert result.chapter_3_10_compliant is True
        assert len(result.missing_requirements) == 0
    
    def test_should_fail_if_corridor_width_less_than_1_6m(self, service):
        """Test falla si ancho de corredor < 1.6m"""
        # Arrange
        farm_data = Mock()
        farm_data.has_antislip_ramps = True
        farm_data.corridor_width_meters = 1.4      # < 1.6m ‚ùå
        farm_data.space_per_animal_m2 = 2.5
        farm_data.has_disinfection_system = True
        farm_data.has_quarantine_corral = True
        farm_data.prohibits_pain_instruments = True
        
        # Act
        result = service.validate_chapter_3_10(farm_data)
        
        # Assert
        assert result.is_compliant is False
        assert result.chapter_3_10_compliant is False
        assert 'corredor_ancho' in result.missing_requirements
    
    def test_should_fail_if_space_per_animal_less_than_2m2(self, service):
        """Test falla si espacio por animal < 2m¬≤"""
        # Arrange
        farm_data = Mock()
        farm_data.has_antislip_ramps = True
        farm_data.corridor_width_meters = 1.8
        farm_data.space_per_animal_m2 = 1.5         # < 2m¬≤ ‚ùå
        farm_data.has_disinfection_system = True
        farm_data.has_quarantine_corral = True
        farm_data.prohibits_pain_instruments = True
        
        # Act
        result = service.validate_chapter_3_10(farm_data)
        
        # Assert
        assert result.is_compliant is False
        assert result.chapter_3_10_compliant is False
        assert 'espacio_por_animal' in result.missing_requirements
    
    def test_should_validate_chapter_7_1_requirements_sanitarios(self, service):
        """Test validaci√≥n de cap√≠tulo 7.1 - Requisitos sanitarios"""
        # Arrange
        farm_data = Mock()
        farm_data.has_veterinary_certificate = True
        farm_data.has_health_register = True
        farm_data.has_vaccination_record = True
        farm_data.has_quarantine_protocol = True
        
        # Act
        result = service.validate_chapter_7_1(farm_data)
        
        # Assert
        assert result.is_compliant is True
        assert result.chapter_7_1_compliant is True
        assert len(result.missing_requirements) == 0
    
    def test_should_fail_if_missing_veterinary_certificate(self, service):
        """Test falla si falta certificado veterinario"""
        # Arrange
        farm_data = Mock()
        farm_data.has_veterinary_certificate = False  # ‚ùå
        farm_data.has_health_register = True
        farm_data.has_vaccination_record = True
        farm_data.has_quarantine_protocol = True
        
        # Act
        result = service.validate_chapter_7_1(farm_data)
        
        # Assert
        assert result.is_compliant is False
        assert result.chapter_7_1_compliant is False
        assert 'certificado_veterinario' in result.missing_requirements
```

### 3.4 Tests de M√©tricas de Precisi√≥n (Python)

```python
# tests/core/test_precision_metrics.py
import pytest
from app.core.metrics.precision_calculator import PrecisionCalculator
from app.core.constants.system_metrics import SystemMetrics

class TestPrecisionMetrics:
    @pytest.fixture
    def calculator(self):
        return PrecisionCalculator()
    
    def test_should_calculate_r2_score_above_threshold(self, calculator):
        """Test c√°lculo de R¬≤ ‚â• 0.95 (m√©trica cr√≠tica del SCRUM)"""
        # Arrange
        actual_weights = [450, 520, 380, 600, 480, 550, 420]
        predicted_weights = [445, 525, 375, 605, 475, 555, 415]
        
        # Act
        r2_score = calculator.calculate_r2_score(actual_weights, predicted_weights)
        
        # Assert
        assert r2_score >= SystemMetrics.MIN_R2, f"R¬≤ {r2_score} debe ser ‚â• {SystemMetrics.MIN_R2}"
    
    def test_should_calculate_mae_below_5kg_threshold(self, calculator):
        """Test error absoluto promedio < 5kg (m√©trica cr√≠tica del SCRUM)"""
        # Arrange
        actual_weights = [450, 520, 380, 600, 480, 550, 420]
        predicted_weights = [445, 525, 375, 605, 475, 555, 415]
        
        # Act
        mae = calculator.calculate_mae(actual_weights, predicted_weights)
        
        # Assert
        assert mae < SystemMetrics.MAX_ERROR_KG, f"MAE {mae}kg debe ser < {SystemMetrics.MAX_ERROR_KG}kg"
    
    def test_should_calculate_precision_above_95_percent(self, calculator):
        """Test precisi√≥n ‚â• 95% (m√©trica cr√≠tica del SCRUM)"""
        # Arrange
        actual_weights = [450, 520, 380, 600, 480, 550, 420]
        predicted_weights = [445, 525, 375, 605, 475, 555, 415]
        
        # Act
        precision = calculator.calculate_precision(actual_weights, predicted_weights)
        
        # Assert
        assert precision >= SystemMetrics.MIN_PRECISION, f"Precisi√≥n {precision} debe ser ‚â• {SystemMetrics.MIN_PRECISION}"
    
    def test_should_fail_if_precision_below_threshold(self, calculator):
        """Test falla si precisi√≥n < 95%"""
        # Arrange
        actual_weights = [450, 520, 380, 600, 480, 550, 420]
        predicted_weights = [400, 480, 320, 550, 420, 500, 370]  # Errores grandes
        
        # Act & Assert
        with pytest.raises(PrecisionBelowThresholdException) as exc_info:
            calculator.validate_precision_threshold(actual_weights, predicted_weights)
        
        assert "Precisi√≥n" in str(exc_info.value)
        assert "95%" in str(exc_info.value)
```

## 4. Tests de Integraci√≥n

### 4.1 Test de Flujo Completo de Captura (Flutter)

```dart
// test/integration/capture_flow_test.dart
import 'package:flutter_test/flutter_test.dart';
import 'package:integration_test/integration_test.dart';
import 'package:bovine_weight_estimation/main.dart' as app;

void main() {
  IntegrationTestWidgetsFlutterBinding.ensureInitialized();
  
  group('Flujo Completo de Captura - Hacienda Gamelera', () {
    testWidgets('should complete full capture flow for Brahman breed', (tester) async {
      // Arrange
      app.main();
      await tester.pumpAndSettle();
      
      // Act - Navegar a pantalla de captura
      await tester.tap(find.text('Captura de Peso'));
      await tester.pumpAndSettle();
      
      // Act - Seleccionar raza Brahman
      await tester.tap(find.byType(BreedDropdown));
      await tester.pumpAndSettle();
      await tester.tap(find.text('Brahman'));
      await tester.pumpAndSettle();
      
      // Act - Iniciar captura continua
      await tester.tap(find.text('Iniciar Captura'));
      await tester.pumpAndSettle();
      
      // Assert - Verificar que inicia captura
      expect(find.text('Capturando fotogramas...'), findsOneWidget);
      
      // Act - Esperar captura (simulada)
      await tester.pump(Duration(seconds: 5));
      
      // Assert - Verificar evaluaci√≥n de calidad
      expect(find.text('Evaluando calidad...'), findsOneWidget);
      
      // Act - Esperar evaluaci√≥n
      await tester.pump(Duration(seconds: 2));
      
      // Assert - Verificar selecci√≥n del mejor fotograma
      expect(find.text('Seleccionando mejor fotograma...'), findsOneWidget);
      
      // Act - Esperar selecci√≥n
      await tester.pump(Duration(seconds: 1));
      
      // Assert - Verificar resultado
      expect(find.text('Captura exitosa'), findsOneWidget);
      expect(find.textContaining('kg'), findsOneWidget);
      
      // Assert - Verificar que se guard√≥ localmente (offline-first)
      expect(find.text('Guardado localmente'), findsOneWidget);
    });
    
    testWidgets('should validate all 7 breeds in capture flow', (tester) async {
      // Arrange
      app.main();
      await tester.pumpAndSettle();
      
      final breeds = [
        'Brahman', 'Nelore', 'Angus', 'Cebuinas (Bos indicus)',
        'Criollo (Bos taurus)', 'Pardo Suizo', 'Jersey'
      ];
      
      // Act & Assert - Verificar que todas las razas est√°n disponibles
      await tester.tap(find.text('Captura de Peso'));
      await tester.pumpAndSettle();
      
      await tester.tap(find.byType(BreedDropdown));
      await tester.pumpAndSettle();
      
      for (final breed in breeds) {
        expect(find.text(breed), findsOneWidget,
          reason: 'Raza $breed debe estar disponible para Hacienda Gamelera');
      }
    });
  });
}
```

### 4.2 Test de Generaci√≥n de GMA (Python)

```python
# tests/integration/test_gma_generation_flow.py
import pytest
from fastapi.testclient import TestClient
from app.main import app
from app.models.gma import GMA
from app.models.regensa_compliance import REGENSACompliance

client = TestClient(app)

class TestGMAGenerationFlow:
    def test_should_generate_gma_with_regensa_compliance(self):
        """Test flujo completo de generaci√≥n de GMA con validaci√≥n REGENSA"""
        # Arrange
        farm_id = "hacienda_gamelera_001"
        animal_ids = ["animal_001", "animal_002", "animal_003"]
        destination = "Matadero San Ignacio"
        
        # Act 1 - Validar cumplimiento REGENSA
        compliance_response = client.post(
            "/regensa/validate-compliance",
            json={"farm_id": farm_id}
        )
        
        # Assert 1 - Verificar cumplimiento
        assert compliance_response.status_code == 200
        compliance_data = compliance_response.json()
        assert compliance_data["chapter_3_10_compliant"] is True
        assert compliance_data["chapter_7_1_compliant"] is True
        
        # Act 2 - Crear GMA
        gma_response = client.post(
            "/gma/create",
            json={
                "animal_ids": animal_ids,
                "origin_farm_id": farm_id,
                "destination": destination
            }
        )
        
        # Assert 2 - Verificar GMA creada
        assert gma_response.status_code == 200
        gma_data = gma_response.json()
        assert gma_data["gma_number"] is not None
        assert gma_data["status"] == "Pendiente"
        assert gma_data["regensa_compliance"]["chapter_3_10_compliant"] is True
        assert gma_data["regensa_compliance"]["chapter_7_1_compliant"] is True
    
    def test_should_fail_gma_creation_without_regensa_compliance(self):
        """Test falla creaci√≥n de GMA sin cumplimiento REGENSA"""
        # Arrange
        farm_id = "farm_non_compliant"
        animal_ids = ["animal_001"]
        destination = "Destino"
        
        # Act - Intentar crear GMA sin cumplimiento
        response = client.post(
            "/gma/create",
            json={
                "animal_ids": animal_ids,
                "origin_farm_id": farm_id,
                "destination": destination
            }
        )
        
        # Assert - Verificar error
        assert response.status_code == 400
        error_data = response.json()
        assert "No cumple con REGENSA" in error_data["message"]
        assert "missing_requirements" in error_data["detail"]
```

## 5. Performance Testing

### 5.1 Tests de Rendimiento (Flutter)

```dart
// test/performance/capture_performance_test.dart
import 'package:flutter_test/flutter_test.dart';
import 'package:bovine_weight_estimation/features/data_management/domain/usecases/evaluate_frame_quality_usecase.dart';

void main() {
  group('Performance Tests - M√©tricas del SCRUM', () {
    test('should process frame evaluation under 3 seconds', () async {
      // Arrange
      final useCase = EvaluateFrameQualityUseCase();
      final frameData = MockFrameData();
      
      // Act
      final stopwatch = Stopwatch()..start();
      final result = await useCase(frameData: frameData);
      stopwatch.stop();
      
      // Assert
      expect(stopwatch.elapsedMilliseconds, lessThan(3000),
        reason: 'Procesamiento debe ser < 3 segundos (m√©trica SCRUM)');
      expect(result.isRight(), true);
    });
    
    test('should handle 75 frames (maximum) within performance limits', () async {
      // Arrange
      final useCase = EvaluateFrameQualityUseCase();
      final frames = List.generate(75, (index) => MockFrameData());
      
      // Act
      final stopwatch = Stopwatch()..start();
      final results = await Future.wait(
        frames.map((frame) => useCase(frameData: frame))
      );
      stopwatch.stop();
      
      // Assert
      expect(stopwatch.elapsedMilliseconds, lessThan(10000),
        reason: '75 fotogramas deben procesarse en < 10 segundos');
      expect(results.every((result) => result.isRight()), true);
    });
  });
}
```

### 5.2 Tests de Carga (Python)

```python
# tests/performance/test_api_performance.py
import pytest
import time
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

class TestAPIPerformance:
    def test_capture_session_creation_under_3_seconds(self):
        """Test creaci√≥n de sesi√≥n de captura < 3 segundos"""
        # Arrange
        request_data = {
            "animal_id": "test_animal_001",
            "breed_type": "brahman"
        }
        
        # Act
        start_time = time.time()
        response = client.post("/capture-sessions/start", json=request_data)
        end_time = time.time()
        
        # Assert
        processing_time = end_time - start_time
        assert processing_time < 3.0, f"Procesamiento {processing_time}s debe ser < 3s"
        assert response.status_code == 200
    
    def test_senasag_report_generation_performance(self):
        """Test generaci√≥n de reporte SENASAG con rendimiento aceptable"""
        # Arrange
        request_data = {
            "period_start": "2024-01-01T00:00:00Z",
            "period_end": "2024-01-31T23:59:59Z",
            "report_type": "Inventario"
        }
        
        # Act
        start_time = time.time()
        response = client.post("/senasag/generate-report", json=request_data)
        end_time = time.time()
        
        # Assert
        processing_time = end_time - start_time
        assert processing_time < 10.0, f"Generaci√≥n de reporte {processing_time}s debe ser < 10s"
        assert response.status_code == 200
```

## 6. Configuraci√≥n de Testing

### 6.1 Configuraci√≥n Flutter (pubspec.yaml)

```yaml
dev_dependencies:
  flutter_test:
    sdk: flutter
  integration_test:
    sdk: flutter
  mockito: ^5.4.2
  build_runner: ^2.4.7
  
  # Testing espec√≠fico del dominio
  test: ^1.24.0
  bloc_test: ^9.1.5
  golden_toolkit: ^0.15.0
  
flutter:
  test:
    # Configuraci√≥n para tests de las 7 razas
    test_directories:
      - test/
      - test/features/
      - test/core/
      - test/integration/
      - test/performance/
```

### 6.2 Configuraci√≥n Python (pytest.ini)

```ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    --cov=app
    --cov-report=html
    --cov-report=term-missing
    --cov-fail-under=70
    --verbose
    --tb=short

# Configuraci√≥n espec√≠fica del proyecto
markers =
    critical: Tests cr√≠ticos (100% cobertura obligatoria)
    breeds: Tests de las 7 razas espec√≠ficas
    regulatory: Tests de integraci√≥n normativa
    performance: Tests de rendimiento
    integration: Tests de integraci√≥n

# Filtros para tests espec√≠ficos
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
```

### 6.3 Scripts de Testing

```bash
#!/bin/bash
# scripts/run_tests.sh

echo "üß™ Ejecutando tests del Sistema de Estimaci√≥n de Peso Bovino"

# Tests Flutter
echo "üì± Ejecutando tests Flutter..."
flutter test --coverage
flutter test integration_test/ --coverage

# Tests Python
echo "üêç Ejecutando tests Python..."
pytest tests/ --cov=app --cov-report=html

# Tests cr√≠ticos (100% cobertura obligatoria)
echo "üéØ Ejecutando tests cr√≠ticos..."
pytest tests/ -m critical --cov=app --cov-fail-under=100

# Tests de las 7 razas espec√≠ficas
echo "üêÑ Ejecutando tests de razas bovinas..."
pytest tests/ -m breeds --cov=app

# Tests de integraci√≥n normativa
echo "üìã Ejecutando tests normativos..."
pytest tests/ -m regulatory --cov=app

# Tests de rendimiento
echo "‚ö° Ejecutando tests de rendimiento..."
pytest tests/ -m performance

echo "‚úÖ Tests completados"
```
